{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "raw_data = load_wine()\n",
    "data = raw_data.data\n",
    "feature_names = raw_data.feature_names\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df['target'] = raw_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи используется линейный классификатор, поэтому имеет смысл искать искомое подмножество признаков, основываясь на их множественной корреляции Пирсона с целевой переменной - высокая корреляция показывает, что классы хорошо линейно разделяются по целевому признаку. Будем перебирать всевозможные подмножества признаков и остановимся, когда множественная корреляция перестанет значительно расти при увеличении мощности подмножеств. Искомые признаки выберем из числа рассмотренных подмножеств наибольшей мощности, на которых достигается максимум множественной кореляции.\n",
    "\n",
    "Кроме того, поскольку целевой признак - категориальный, чтобы исключить влияние искуственно введенного на нем порядка, будем рассматривать всевозможные перестановки его значений (т.е. перестановки чисел, соответствующих классам). Можно сузить число уникальных перестановок до 3ех, т.к. , например, (0, 1, 2) и (2, 1, 0) дадут равные по модулю коэффициенты множественной корреляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def target_permutation(perm, target):\n",
    "    temp = np.copy(target)\n",
    "    temp = np.where(temp==0, 3, temp)\n",
    "    temp = np.where(temp==1, 4, temp)\n",
    "    temp = np.where(temp==2, perm[2], temp)\n",
    "    temp = np.where(temp==3, perm[0], temp)\n",
    "    temp = np.where(temp==4, perm[1], temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_mul_correlation(x, m):\n",
    "    corr_matrix = np.zeros((len(m), len(m)))\n",
    "    c = np.zeros(len(m))\n",
    "    \n",
    "    for i in range(len(m)):\n",
    "        c[i] = st.pearsonr(x, np.argsort(np.argsort(df[m[i]])))[0]\n",
    "        for j in range(len(m)):\n",
    "            corr_matrix[i][j] = st.pearsonr(np.argsort(np.argsort(df[m[i]])),\n",
    "                                            np.argsort(np.argsort(df[m[j]])))[0]\n",
    "    R = np.linalg.inv(corr_matrix)\n",
    "    return c @ R @ c.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 0\n",
    "squared_mul_corr = []\n",
    "r = 0\n",
    "target = df[df.columns[-1]]\n",
    "\n",
    "for column_set in powerset(df.columns[:-1]):\n",
    "    if len(column_set) > 0:\n",
    "        for perm in ([0, 1, 2], [1, 0, 2], [2, 0, 1]):\n",
    "            perm_target = target_permutation(perm, target)\n",
    "            squared_mul_corr.append(squared_mul_correlation(perm_target, column_set))\n",
    "        if n_features != len(column_set):\n",
    "            n_features += 1\n",
    "            if abs(r - max(squared_mul_corr)) < 5e-2:\n",
    "                break\n",
    "            else:\n",
    "                r = max(squared_mul_corr)\n",
    "                squared_mul_corr = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_mul_corr = []\n",
    "sets = []\n",
    "for column_set in powerset(df.columns[:-1]):\n",
    "    if len(column_set) == n_features:\n",
    "        for perm in ([0, 1, 2], [1, 0, 2], [2, 0, 1]):\n",
    "            perm_target = target_permutation(perm, target)\n",
    "            squared_mul_corr.append(squared_mul_correlation(perm_target, column_set)) \n",
    "            sets.append(column_set)\n",
    "important_features = list(sets[np.argmax(np.array(squared_mul_corr))])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее важные признаки: ['flavanoids', 'color_intensity', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(\"Наиболее важные признаки: {}\".format(important_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним качество линейной классификации на полном множестве признаков и найденном нами подмножестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()), (\"logreg\", LogisticRegression())])\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "cross_val_score(pipe, raw_data.data, raw_data.target, cv=cv).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444443"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"scale\", StandardScaler()), (\"logreg\", LogisticRegression())])\n",
    "cross_val_score(pipe, df[important_features], raw_data.target, cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимум качества классификации по всем подвыборкам признаков той же мощности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.5802469135802469,  mean: 0.8185919019252352,  max: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for column_set in powerset(df.columns[:-1]):\n",
    "    if len(column_set) == n_features:\n",
    "        pipe = Pipeline([(\"scale\", StandardScaler()), (\"logreg\", LogisticRegression())])\n",
    "        scores.append(cross_val_score(pipe, df[list(column_set)], raw_data.target, cv=cv).mean())\n",
    "print(\"min: {},  mean: {},  max: {}\".format(min(scores), sum(scores) / len(scores), max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что найденные признаки гораздо лучше разделяются по целевой переменной линейной гиперплоскостью, чем в среднем по всевозможным наборам из 3ех признаков.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
